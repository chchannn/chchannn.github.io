import numpy as np
import pandas as pd
import torch

from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt
import seaborn as sns


def l2_dist(x, y):
    """
    Calculating L2 distances using matraix operations
    """
    xx, yy, zz = torch.mm(x, x.t()), torch.mm(y, y.t()), torch.mm(x, y.t())
    rx = (xx.diag().unsqueeze(0).expand_as(xx))
    ry = (yy.diag().unsqueeze(0).expand_as(yy))

    dxx = rx.t() + rx - 2. * xx
    dyy = ry.t() + ry - 2. * yy
    dxy = rx.t() + ry - 2. * zz
    return -0.5*(dxx + dyy - 2*dxy)


X, y = make_blobs(n_samples=1000, centers=2, n_features=2,
                  random_state=0)
colors = ['red', 'blue']
ax = sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, palette=colors, alpha=0.5, s=7)

means = np.vstack([X[y == i].mean(axis=0) for i in range(2)])
ax = sns.scatterplot(x=means[:, 0], y=means[:, 1], hue=range(2), palette=colors, s=50, ec='black', legend=False, ax=ax)

sns.lineplot(x=means[:, 0], y=means[:, 1], markers=True, ax=ax)
plt.title("Distance Between the Centers of Two Distributions in a 2D Space")


center0 = torch.tensor(means[0]).unsqueeze(0)
center1 = torch.tensor(means[1]).unsqueeze(0)

# make sure the l2 dist function is correct
assert l2_dist(center0 , center1) == ((center0 - center1)**2).sum(axis=1)



import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal
from scipy.stats import dirichlet 
from torch.distributions.multivariate_normal import MultivariateNormal 


m = 20 # sample size
x_mean = torch.zeros(2)+1
y_mean = torch.zeros(2)
x_cov = 2*torch.eye(2) # IMPORTANT: Covariance matrices must be positive definite
y_cov = 3*torch.eye(2) - 1

px = MultivariateNormal(x_mean, x_cov)
qy = MultivariateNormal(y_mean, y_cov)
x = px.sample([m]).to(device)
y = qy.sample([m]).to(device)




import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def MMD(x, y, kernel):
    """Emprical maximum mean discrepancy. The lower the result
       the more evidence that distributions are the same.

    Args:
        x: first sample, distribution P
        y: second sample, distribution Q
        kernel: kernel type such as "multiscale" or "rbf"
    """
    xx, yy, zz = torch.mm(x, x.t()), torch.mm(y, y.t()), torch.mm(x, y.t())
    rx = (xx.diag().unsqueeze(0).expand_as(xx))
    ry = (yy.diag().unsqueeze(0).expand_as(yy))
    
    dxx = rx.t() + rx - 2. * xx 
    dyy = ry.t() + ry - 2. * yy 
    dxy = rx.t() + ry - 2. * zz 
    
    XX, YY, XY = (torch.zeros(xx.shape).to(device),
                  torch.zeros(xx.shape).to(device),
                  torch.zeros(xx.shape).to(device))

    if kernel == "none":
        bandwidth_range = [1]
        for a in bandwidth_range:

            XX += -dxx*a*0.5
            YY += -dyy*a*0.5
            XY += -dxy*a*0.5

    
    if kernel == "multiscale":
        
        bandwidth_range = [0.2, 0.5, 0.9, 1.3]
        for a in bandwidth_range:
            XX += a**2 * (a**2 + dxx)**-1
            YY += a**2 * (a**2 + dyy)**-1
            XY += a**2 * (a**2 + dxy)**-1
            
    if kernel == "rbf":
      
        bandwidth_range = [10, 15, 20, 50]
        for a in bandwidth_range:
            XX += torch.exp(-0.5*dxx/a)
            YY += torch.exp(-0.5*dyy/a)
            XY += torch.exp(-0.5*dxy/a)
      
      

    return torch.mean(XX + YY - 2. * XY)


MMD(x, y, kernel="multiscale")
